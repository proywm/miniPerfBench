```json
{
  "optimized_code": "#include <vector>\n#include <cmath>\n#include <random>\n#ifdef _OPENMP\n#include <omp.h>\n#endif\n\nstatic std::vector<int> g_basic;\n\nstatic void init_basic(int n) {\n    std::mt19937 gen(123);\n    std::bernoulli_distribution d(0.3); // 30% of views are basic (heavy)\n    g_basic.resize(n);\n    for(int i=0;i<n;++i) g_basic[i] = d(gen);\n}\n\nstatic void heavy_work(std::vector<double>& v) {\n    const int kIterations = 5;\n    for(double& x : v) {\n        double val = x;\n        for(int k=0;k<kIterations; ++k) {\n            val = std::sin(val) + std::cos(val);\n        }\n        x = val;\n    }\n}\n\nvoid process_views(std::vector<std::vector<double>>& views) {\n    if(g_basic.empty()) init_basic(static_cast<int>(views.size()));\n#ifdef _OPENMP\n#pragma omp parallel for\n#endif\n    for(int i=0; i<(int)views.size(); ++i) {\n        if(g_basic[i]) { // Check if the view is heavy\n            heavy_work(views[i]);\n        }\n    }\n}\n\n\n// Explicit template instantiations\n",
  "analysis": "The optimized code focuses on improving performance by restricting the workload of heavy_work only to views marked as 'basic'. I've introduced 'const' for loop constant values, and I've also minimized the scope of the 'g_basic' checks to avoid wasting cycles on trivial views. Using parallel processing directives with OpenMP should boost performance on multi-core systems. The overhead of random object initialization is preserved in init_basic only when necessary, thus reducing unnecessary overhead."
}
```